{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "This notebook checks that the number of comments extracted from all pages of a game's xml matches the claimed number of comments on the first page of xml for each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boardgamegeek import BGGClient\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from proxy_requests.proxy_requests import ProxyRequests\n",
    "from retry import retry\n",
    "import time\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a helper function to get the path for the spark context. If I develop many other commonly used helper\n",
    "#functions I will wrap them up into a module.\n",
    "def local_path(path):\n",
    "    \n",
    "    return 'file://'+str(os.path.abspath(os.path.curdir))+'/'+path\n",
    "\n",
    "sc = SparkContext('local[*]','temp')\n",
    "\n",
    "files = sc.wholeTextFiles(local_path('Data/*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator(xml):\n",
    "    # This function will be used by map to give the game id as key and a tuple [total,comments_count] \n",
    "    # where total is either 0 or if the xml is the first page of xml the total expected comment count\n",
    "    # comments count is the count of comments on the page\n",
    "    \n",
    "    #get the game id form the directory name\n",
    "    key = ((xml[0]).split('/')[-1]).split('_')[0]\n",
    "    \n",
    "    #soupify the xml\n",
    "    soup = BeautifulSoup(xml[1])\n",
    "    \n",
    "    #see if it's the first page to get expected total comment count\n",
    "    try:\n",
    "    \n",
    "        total = int(soup.comments['totalitems'])\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        total = 0\n",
    "    \n",
    "    \n",
    "    return (key, [total, len(soup.find_all('comment'))])\n",
    "\n",
    "def user_rating_parser(xml):\n",
    "    # This function will return an rdd with game_id as key and a tuple as value\n",
    "    # where the tuple is [user,rating]\n",
    "    \n",
    "    #get game id as key\n",
    "    key = ((xml[0]).split('/')[-1]).split('_')[0]\n",
    "    \n",
    "    soup = BeautifulSoup(xml[1])\n",
    "    \n",
    "    comments = soup.find_all('comment')\n",
    "    \n",
    "    # get rating and username for each comment and yield k,v pair\n",
    "    for comment in comments:\n",
    "        \n",
    "        user = comment.get('username')\n",
    "        \n",
    "        rating = comment.get('rating')\n",
    "        \n",
    "        yield (key,[user,float(rating)])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def add_tuples(a,b):\n",
    "    #This function allows adding of values in a reduceByKey call\n",
    "    return [a[0]+b[0],a[1]+b[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get the expected and actual comment counts by game\n",
    "comment_counts = files.map(aggregator).reduceByKey(add_tuples).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 games that had more than 0.01% of comments dropped or added \n",
      " (where 0.01% corresponds to at least 10 comments)\n"
     ]
    }
   ],
   "source": [
    "#Let's check for any games where we may have dropped some comments. \n",
    "#We will look to see if more than .1% of comments have been dropped.\n",
    "#If the quantity is not zero, go back and scrape those games again.\n",
    "count=0\n",
    "for c in comment_counts:\n",
    "    \n",
    "    if abs((c[1][0]-c[1][1])/c[1][0])*100 > 0.01 and abs(c[1][0]-c[1][1])>10:\n",
    "        \n",
    "        print(c)\n",
    "        count+=1\n",
    "        \n",
    "print('There were',count,'games that had more than 0.01% of comments dropped or added \\n (where 0.01% corresponds to at least 10 comments)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
